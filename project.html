<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="shortcut icon" href="images/favicon.png" />
    <link rel="stylesheet" type="text/css" href="css/html5reset.css">
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <title >Lusi(Ruth) Wang</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-138454362-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-138454362-1');
    </script>
</head>

<body class="wrapper_grid">
  <a class="skip-main" href="#content">Skip to main content</a>

  <nav>
      <ul class="navigations">
        <li><a href="index.html"> highlight </a></li>
        <li><a href="conference.html"> conference  </a></li>
        <li><a href="journey.html"> journey </a></li>
        <li><a href="contact.html"> contact </a></li>
      </ul>
  </nav>

  <main id = "content" class="proj_grid" tabindex="-1">
    <h2>ORBit - VR Musical Interface</h2>

    <div>
      <p class="intro">
        ORBit is a new “impossible” instrument in VR that is played by grabbing and moving the sound orbs around in the space. The y-axis is mapped to pitch, and is locked to a D scale. The user can choose between chromatic, major, and minor tonalities via a semi-diagetic menu in the scene. The two effects objects (floating lights) represent a low-pass filter and a distortion filter, and both will apply their effects proportionally to any sound orb in their proximity.
      </p>
    </div>

    <button class="accordion">Control</button>
    <div class="panel">
      <p>Hands and grabbing is the core control for ORBit, which we built base on Oculus sample assets. All of the sound mapping is handled through scripting - the usable portion of the y-axis is divided into ‘note zones’, and each orb’s pitch is changed based on which zone it’s in. Our original idea was to map effect parameters to the other axes, but we took some professorial advice and utilized objects instead to make the experience more cohesive.
      </p>
    </div>

    <button class="accordion">Audio</button>
    <div class="panel">
      <p>The audio design for ORBit stemmed from the idea that we would have continuous drones affected in game by various effects.The drones consist of a bass, root, 3rd and 5th, but when pitch shifting is added, you are able to change these designations. We eventually settled on having a bass note and three others at the same pitch an octave above, as this makes visualizing chords and intervals more intuitive.
      </p>
    </div>

    <button class="accordion">Visual</button>
    <div class="panel">
      <p>Since the basic game mechanics for ORBit is based on the Cartesian coordinates, the visual design aimed to enhance the audio experience and make the playing of ORBit more enjoyable. We explored multiple ways to achieve this and landed on using the particle systems for mainly two reasons: 1. It’s less taxing on the computing power for visual rendering. Ensuring a non-interrupted experience takes a high priority; 2. We can easily script interactions using public parameters in the particle system modules.
      </p>
    </div>


  </main>
  <script src = "accordion.js">
  </script>
</body>
</html>
